{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":95687,"databundleVersionId":11858416,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 1: Install necessary libraries\n!pip install timm faiss-cpu albumentations pytorch-metric-learning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:11.257373Z","iopub.execute_input":"2025-04-21T18:52:11.258147Z","iopub.status.idle":"2025-04-21T18:52:14.399700Z","shell.execute_reply.started":"2025-04-21T18:52:11.258117Z","shell.execute_reply":"2025-04-21T18:52:14.398941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Import libraries\nimport os\nimport cv2\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\n# PyTorch imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\n\n# Image processing\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Models\nimport timm\n\n# For hard triplet mining\nfrom pytorch_metric_learning import miners, losses\n\n# For similarity search\nimport faiss\n\n# Set warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seed for reproducibility\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Check for multiple GPUs\nif torch.cuda.is_available():\n    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:14.401303Z","iopub.execute_input":"2025-04-21T18:52:14.401580Z","iopub.status.idle":"2025-04-21T18:52:19.496106Z","shell.execute_reply.started":"2025-04-21T18:52:14.401549Z","shell.execute_reply":"2025-04-21T18:52:19.495309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3: Configuration with debug info\n# Paths\nDATA_DIR = '/kaggle/input/tammathon-task-1'\nprint(f\"DATA_DIR exists: {os.path.exists(DATA_DIR)}\")\n\nTRAIN_IMG_DIR = DATA_DIR + '/train'\nprint(f\"TRAIN_IMG_DIR exists: {os.path.exists(TRAIN_IMG_DIR)}\")\n\nVAL_IMG_DIR = DATA_DIR + '/val'\nprint(f\"VAL_IMG_DIR exists: {os.path.exists(VAL_IMG_DIR)}\")\n\nOUTPUT_DIR = './model_outputs'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"OUTPUT_DIR created: {os.path.exists(OUTPUT_DIR)}\")\n\n# Model parameters\nIMG_SIZE = 256  # Using 256×256 for better accuracy\nEMB_DIM = 512   # Embedding dimension\nBATCH_SIZE = 64 \nNUM_WORKERS = 2\nEPOCHS = 15\nLR = 3e-4\nMARGIN = 0.3   # For triplet loss\n\n# Load CSV files\ntry:\n    print(f\"Trying to load train CSV from: {os.path.join(DATA_DIR, 'train.csv')}\")\n    print(f\"File exists: {os.path.exists(os.path.join(DATA_DIR, 'train.csv'))}\")\n    train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Train DataFrame columns: {train_df.columns.tolist()}\")\n    print(train_df.head(2))\n\n    # Rename the 'filename' column to 'path'\n    train_df.rename(columns={'filename': 'path'}, inplace=True)\n\nexcept Exception as e:\n    print(f\"Error loading train CSV: {e}\")\n\ntry:\n    print(f\"Trying to load val CSV from: {os.path.join(DATA_DIR, 'val.csv')}\")\n    print(f\"File exists: {os.path.exists(os.path.join(DATA_DIR, 'val.csv'))}\")\n    val_df = pd.read_csv(os.path.join(DATA_DIR, 'val.csv'))\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Val DataFrame columns: {val_df.columns.tolist()}\")\n    print(val_df.head(2))\n\n    # Rename the 'filename' column to 'path'\n    val_df.rename(columns={'filename': 'path'}, inplace=True)\n\nexcept Exception as e:\n    print(f\"Error loading val CSV: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:19.496872Z","iopub.execute_input":"2025-04-21T18:52:19.497491Z","iopub.status.idle":"2025-04-21T18:52:19.799673Z","shell.execute_reply.started":"2025-04-21T18:52:19.497456Z","shell.execute_reply":"2025-04-21T18:52:19.799064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Finding and Displaying Sample Images\n\n# Let's properly explore the directory structure and find images\ndef find_sample_images(base_dir, num_samples=3):\n    \"\"\"Find and return paths to sample images in the dataset\"\"\"\n    image_paths = []\n    \n    print(f\"Exploring directory structure in {base_dir}...\")\n    # List top-level contents\n    contents = os.listdir(base_dir)\n    print(f\"Top-level contents: {contents[:5]}\")\n    \n    # If there's a 'train' subdirectory inside the base_dir, use that\n    if 'train' in contents and os.path.isdir(os.path.join(base_dir, 'train')):\n        train_dir = os.path.join(base_dir, 'train')\n        print(f\"Found train subdirectory: {train_dir}\")\n        \n        # List cat folders\n        cat_folders = os.listdir(train_dir)[:10]  # First 10 cat folders\n        print(f\"Cat folders: {cat_folders}\")\n        \n        # Go through some cat folders to find images\n        for cat_folder in cat_folders[:5]:  # Check first 5 cat folders\n            cat_path = os.path.join(train_dir, cat_folder)\n            if os.path.isdir(cat_path):\n                print(f\"Looking in {cat_path}...\")\n                files = [f for f in os.listdir(cat_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n                if files:\n                    print(f\"Found {len(files)} images, e.g., {files[:3]}\")\n                    # Add full paths to some images\n                    for file in files[:num_samples]:\n                        image_paths.append(os.path.join(cat_path, file))\n                    if len(image_paths) >= num_samples:\n                        break\n    \n    return image_paths\n\ndef display_images(image_paths):\n    \"\"\"Display multiple images in a grid\"\"\"\n    n = len(image_paths)\n    if n == 0:\n        print(\"No images to display\")\n        return\n    \n    # Calculate grid dimensions\n    cols = min(n, 3)\n    rows = (n + cols - 1) // cols\n    \n    plt.figure(figsize=(cols * 4, rows * 4))\n    for i, path in enumerate(image_paths):\n        try:\n            img = cv2.imread(path)\n            if img is None:\n                print(f\"Could not read image at {path}\")\n                continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            plt.subplot(rows, cols, i + 1)\n            plt.imshow(img)\n            plt.title(f\"Cat Image {i+1}\\n{os.path.basename(os.path.dirname(path))}\")\n            plt.axis('off')\n        except Exception as e:\n            print(f\"Error displaying image {path}: {e}\")\n    \n    plt.tight_layout()\n    plt.show()\n\n# Fix the file paths based on the directory structure we discovered\ndef construct_correct_path(filename, train_dir, data_dir):\n    \"\"\"Construct the correct file path based on the dataset structure\"\"\"\n    # If filename starts with 'train/', check if path should include the extra 'train' directory\n    if filename.startswith('train/'):\n        # Try the direct path first (with single 'train')\n        direct_path = os.path.join(data_dir, filename)\n        if os.path.exists(direct_path):\n            return direct_path\n        \n        # Try with extra 'train' directory\n        parts = filename.split('/')\n        if len(parts) >= 2:\n            # Reconstruct path with extra 'train' directory\n            extra_train_path = os.path.join(train_dir, 'train', parts[1], parts[2])\n            if os.path.exists(extra_train_path):\n                return extra_train_path\n    \n    return None\n\n# Find some sample images from the dataset\ntry:\n    # Find sample images by exploring directory structure\n    sample_paths = find_sample_images(TRAIN_IMG_DIR)\n    \n    if sample_paths:\n        print(f\"\\nFound {len(sample_paths)} sample images:\")\n        for path in sample_paths:\n            print(f\" - {path}\")\n        \n        # Display the images\n        display_images(sample_paths)\n    else:\n        print(\"\\nCould not find sample images through directory exploration.\")\n        \n        # Try another approach using the CSV filenames\n        print(\"\\nTrying to construct paths from CSV filenames...\")\n        sample_paths = []\n        for idx in range(min(5, len(train_df))):\n            filename = train_df['filename'][idx]\n            correct_path = construct_correct_path(filename, TRAIN_IMG_DIR, DATA_DIR)\n            \n            if correct_path and os.path.exists(correct_path):\n                print(f\"Found valid path for {filename}: {correct_path}\")\n                sample_paths.append(correct_path)\n            else:\n                # Try one more approach - direct concatenation with the train dir\n                possible_path = os.path.join(TRAIN_IMG_DIR, filename)\n                if os.path.exists(possible_path):\n                    print(f\"Found via direct concatenation: {possible_path}\")\n                    sample_paths.append(possible_path)\n        \n        if sample_paths:\n            display_images(sample_paths)\n        else:\n            print(\"Could not find any valid image paths.\")\n            \n            # Last resort - print out some directories to help debug\n            print(\"\\nListing some directories to help debug:\")\n            data_dir_contents = os.listdir(DATA_DIR)\n            print(f\"DATA_DIR contents: {data_dir_contents}\")\n            \n            train_dir_contents = os.listdir(TRAIN_IMG_DIR)\n            print(f\"TRAIN_IMG_DIR contents: {train_dir_contents[:10]}\")\n\nexcept Exception as e:\n    print(f\"Error during path exploration: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:19.801154Z","iopub.execute_input":"2025-04-21T18:52:19.801380Z","iopub.status.idle":"2025-04-21T18:52:20.722497Z","shell.execute_reply.started":"2025-04-21T18:52:19.801362Z","shell.execute_reply":"2025-04-21T18:52:20.721656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5 (Revised): Custom Dataset Class with Fixed Path Construction\n\nclass CatFaceDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        \n        # Get unique cat IDs and map them to indices (for sampling)\n        self.unique_cats = df['label'].unique()\n        self.cat_to_indices = {}\n        for cat_id in self.unique_cats:\n            self.cat_to_indices[cat_id] = df.index[df['label'] == cat_id].tolist()\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_name = row['filename']\n        label = row['label']\n        \n        # Fix path construction based on our directory exploration\n        # We saw that images are in /kaggle/input/tammathon-task-1/train/train/{CAT_ID}/{IMAGE_NUM}.png\n        if img_name.startswith('train/'):\n            # Extract cat_id and image_name from filename (e.g., \"train/092947/00.png\")\n            parts = img_name.split('/')\n            if len(parts) == 3:  # Should have 3 parts: \"train\", \"092947\", \"00.png\"\n                cat_id = parts[1]\n                img_file = parts[2]\n                # Construct proper path with double \"train\"\n                img_path = os.path.join(self.img_dir, 'train', 'train', cat_id, img_file)\n            else:\n                # Fallback\n                img_path = os.path.join(self.img_dir, img_name)\n        else:\n            img_path = os.path.join(self.img_dir, img_name)\n        \n        # Print path for debugging (first few times)\n        if idx < 5:  # Only print for the first 5 items to avoid flooding output\n            print(f\"Loading image from: {img_path}\")\n            print(f\"File exists: {os.path.exists(img_path)}\")\n        \n        # Load and process image\n        img = cv2.imread(img_path)\n        \n        # Check if image was loaded successfully\n        if img is None:\n            print(f\"Failed to load image at {img_path}\")\n            # Create a dummy black image as fallback\n            img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n        else:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            img = self.transform(image=img)['image']\n        \n        return img, label\n\n    def get_label(self, idx):\n        \"\"\"Get the label for a specific index\"\"\"\n        return self.df.iloc[idx]['label']\n    \n    def get_pos_neg_items(self, idx):\n        \"\"\"Get a positive (same cat) and negative (different cat) sample for the anchor at idx\"\"\"\n        anchor_label = self.get_label(idx)\n        \n        # Get a positive sample (same cat, different image)\n        pos_indices = self.cat_to_indices[anchor_label]\n        if len(pos_indices) <= 1:  # If only one image for this cat, use the same image\n            pos_idx = idx\n        else:\n            # Find a different image of the same cat\n            other_indices = [i for i in pos_indices if i != idx]\n            if other_indices:\n                pos_idx = random.choice(other_indices)\n            else:\n                pos_idx = idx\n        \n        # Get a negative sample (different cat)\n        other_cats = [cat for cat in self.unique_cats if cat != anchor_label]\n        neg_cat = random.choice(other_cats)\n        neg_idx = random.choice(self.cat_to_indices[neg_cat])\n        \n        return pos_idx, neg_idx\n\n\n# Let's test our dataset class with a more focused approach\ndef test_dataset_focused(df, img_dir, transform=None, num_samples=3):\n    \"\"\"Test our dataset class with careful error handling\"\"\"\n    dataset = CatFaceDataset(df, img_dir, transform)\n    print(f\"Dataset size: {len(dataset)}\")\n    print(f\"Number of unique cats: {len(dataset.unique_cats)}\")\n    \n    # Try specific indices rather than random ones\n    valid_images = []\n    max_attempts = 20\n    attempts = 0\n    \n    while len(valid_images) < num_samples and attempts < max_attempts:\n        try:\n            idx = attempts  # Try sequential indices\n            img, label = dataset[idx]\n            \n            if isinstance(img, torch.Tensor):\n                # If it's a tensor, it's likely valid\n                valid_images.append((img, label, idx))\n            elif img is not None and img.size > 0:\n                # If it's a numpy array and not empty\n                valid_images.append((img, label, idx))\n                \n        except Exception as e:\n            print(f\"Error with index {idx}: {e}\")\n        \n        attempts += 1\n    \n    # Display valid images\n    if valid_images:\n        plt.figure(figsize=(15, 5))\n        for i, (img, label, idx) in enumerate(valid_images):\n            if i >= num_samples:\n                break\n                \n            if isinstance(img, torch.Tensor):\n                # Convert tensor to numpy for display\n                img = img.permute(1, 2, 0).numpy()\n                # Denormalize if needed\n                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n                img = np.clip(img, 0, 1)\n            \n            plt.subplot(1, num_samples, i + 1)\n            plt.imshow(img)\n            plt.title(f\"Cat ID: {label}\\nIndex: {idx}\")\n            plt.axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"Could not find any valid images after multiple attempts.\")\n        \n        # Debug: print details about a few sample filenames\n        print(\"\\nSample filenames from DataFrame:\")\n        for i in range(5):\n            if i < len(df):\n                filename = df['filename'].iloc[i]\n                print(f\"{i}: {filename}\")\n\n# Now test our dataset with the improved dataset class\ntry:\n    # For test, use simple resize transform without normalization to see original colors\n    test_transform = A.Compose([\n        A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n    ])\n    \n    print(\"Testing training dataset with fixed path construction:\")\n    test_dataset_focused(train_df, DATA_DIR, test_transform)\nexcept Exception as e:\n    print(f\"Error testing dataset: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:20.723284Z","iopub.execute_input":"2025-04-21T18:52:20.723935Z","iopub.status.idle":"2025-04-21T18:53:01.828187Z","shell.execute_reply.started":"2025-04-21T18:52:20.723913Z","shell.execute_reply":"2025-04-21T18:53:01.827469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6.1: Image Transformations\nfrom torchvision import transforms\n\n# Define image transformations\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nprint(\"Image transformations defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:53:01.829129Z","iopub.execute_input":"2025-04-21T18:53:01.829492Z","iopub.status.idle":"2025-04-21T18:53:01.835057Z","shell.execute_reply.started":"2025-04-21T18:53:01.829466Z","shell.execute_reply":"2025-04-21T18:53:01.834376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6.2: Data Loaders\n\nfrom torch.utils.data import DataLoader\n\n# Create full data loaders\ndef create_data_loaders(train_df, val_df, img_dir, batch_size, num_workers):\n    \"\"\"Create training and validation data loaders\"\"\"\n    # Create training dataset\n    train_dataset = CatFaceDataset(\n        df=train_df,\n        img_dir=img_dir,\n        transform=train_transform\n    )\n    \n    # Create validation dataset\n    val_dataset = CatFaceDataset(\n        df=val_df,\n        img_dir=img_dir, \n        transform=val_transform\n    )\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    return train_loader, val_loader, train_dataset, val_dataset\n\n# Call the function to create data loaders\nprint(\"Creating data loaders...\")\ntrain_loader, val_loader, train_dataset, val_dataset = create_data_loaders(\n    train_df, val_df, DATA_DIR, BATCH_SIZE, NUM_WORKERS\n)\n\nprint(f\"Train loader: {len(train_loader)} batches of size {BATCH_SIZE}\")\nprint(f\"Val loader: {len(val_loader)} batches of size {BATCH_SIZE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:53:01.835781Z","iopub.execute_input":"2025-04-21T18:53:01.836054Z","iopub.status.idle":"2025-04-21T18:53:44.594568Z","shell.execute_reply.started":"2025-04-21T18:53:01.836012Z","shell.execute_reply":"2025-04-21T18:53:44.593931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6.3: Fixed Model Architecture and Dataset Issues\n\nimport os\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nimport cv2\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\n\n# Define the dataset class with proper handling of `path_column`\nclass CatFaceDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_train=True):\n        \"\"\"\n        Args:\n            df (DataFrame): Dataframe containing image paths and labels.\n            img_dir (str): Root directory for image files.\n            transform (callable, optional): Transform to be applied to images.\n            is_train (bool): Whether this is a training dataset or validation dataset.\n        \"\"\"\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_train = is_train\n\n        # Find the appropriate column for image paths\n        path_columns = ['image_path', 'path', 'filepath', 'img_path', 'filename']\n        self.path_column = None\n        for col in path_columns:\n            if col in df.columns:\n                self.path_column = col\n                break\n\n        # If no column is found, use the first string column as a fallback\n        if not self.path_column:\n            for col in df.columns:\n                if df[col].dtype == object:\n                    self.path_column = col\n                    break\n        \n        if not self.path_column:\n            raise ValueError(\"No valid path column found in the dataframe!\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            # Get the label\n            label = int(self.df.iloc[idx]['label'])\n\n            # Get the relative image path\n            rel_path = str(self.df.iloc[idx][self.path_column])\n\n            # Build the full image path\n            full_path = os.path.join(self.img_dir, rel_path)\n\n            # Check if the file exists\n            if not os.path.exists(full_path):\n                print(f\"Warning: File not found at {full_path}\")\n                # Return a default blank tensor\n                return torch.zeros((3, 224, 224)), 0\n\n            # Read the image using OpenCV\n            img = cv2.imread(full_path)\n\n            # If the image is None (not found or corrupted), create a blank image\n            if img is None:\n                print(f\"Warning: Could not read image at {full_path}\")\n                img = np.zeros((224, 224, 3), dtype=np.uint8)\n            else:\n                # Convert BGR to RGB\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n            # Convert numpy array to PyTorch tensor\n            img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0  # Scale to [0, 1]\n\n            # Apply the transform (if any)\n            if self.transform:\n                img = self.transform(img)\n\n            return img, label\n\n        except Exception as e:\n            print(f\"Error loading image at index {idx}: {e}\")\n            # Return a default blank tensor\n            return torch.zeros((3, 224, 224)), 0\n\n\n# Define the embedding model architecture\nclass CatEmbeddingModel(nn.Module):\n    def __init__(self, embedding_dim=512):\n        super(CatEmbeddingModel, self).__init__()\n        \n        # Use a pretrained EfficientNet model\n        self.backbone = timm.create_model('efficientnet_b0', pretrained=True)\n        \n        # Replace the classifier with an embedding layer\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Identity()\n        \n        # Add embedding projector to get desired embedding size\n        self.embedding_projector = nn.Sequential(\n            nn.Linear(in_features, embedding_dim),\n            nn.BatchNorm1d(embedding_dim)\n        )\n        \n    def forward(self, x):\n        # Extract features from the backbone\n        features = self.backbone(x)\n        \n        # Project to embedding space\n        embeddings = self.embedding_projector(features)\n        \n        # L2 normalize the embeddings (important for cosine similarity)\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        \n        return embeddings\n\n\n# Initialize the model\nprint(\"Initializing model...\")\nmodel = CatEmbeddingModel(embedding_dim=EMB_DIM)\nmodel = model.to(device)\nprint(f\"Model created with embedding dimension: {EMB_DIM}\")\n\n# Reinitialize datasets (ensure `path_column` is set correctly)\ntrain_dataset = CatFaceDataset(train_df, DATA_DIR, transform=train_transform, is_train=True)\nval_dataset = CatFaceDataset(val_df, DATA_DIR, transform=val_transform, is_train=False)\n\n# Test if datasets are working correctly\ntry:\n    img, label = train_dataset[0]\n    print(f\"Train dataset: Successfully loaded image with shape {img.shape}, label {label}\")\nexcept Exception as e:\n    print(f\"Train dataset test failed: {e}\")\n\ntry:\n    img, label = val_dataset[0]\n    print(f\"Validation dataset: Successfully loaded image with shape {img.shape}, label {label}\")\nexcept Exception as e:\n    print(f\"Validation dataset test failed: {e}\")\n\n# Recreate data loaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nprint(f\"Train loader created with {len(train_loader)} batches.\")\nprint(f\"Validation loader created with {len(val_loader)} batches.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:53:44.595248Z","iopub.execute_input":"2025-04-21T18:53:44.595446Z","iopub.status.idle":"2025-04-21T18:53:45.332357Z","shell.execute_reply.started":"2025-04-21T18:53:44.595424Z","shell.execute_reply":"2025-04-21T18:53:45.331592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6.4: Optimizer and Loss\n\n# Initialize optimizer and loss\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\ntriplet_loss = nn.TripletMarginLoss(margin=MARGIN)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=2, verbose=True\n)\n\nprint(\"Optimizer, loss, and scheduler initialized!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:53:45.333202Z","iopub.execute_input":"2025-04-21T18:53:45.333851Z","iopub.status.idle":"2025-04-21T18:53:45.339741Z","shell.execute_reply.started":"2025-04-21T18:53:45.333830Z","shell.execute_reply":"2025-04-21T18:53:45.338945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Cell 7: Complete Training Loop with Triplet Loss\n\n# import torch.nn.functional as F\n# from torch.cuda.amp import autocast, GradScaler\n# import time\n# import faiss\n# import matplotlib.pyplot as plt\n# import copy\n\n# # Define triplet mining function\n# def get_hard_triplets(embeddings, labels, margin=0.2):\n#     \"\"\"Mine hard triplets from embeddings\"\"\"\n#     # Move tensors to CPU for computation\n#     embeddings = embeddings.detach().cpu()\n#     labels = labels.detach().cpu()\n    \n#     # Calculate pairwise distances\n#     distances = torch.cdist(embeddings, embeddings)\n    \n#     # Create masks for positive and negative pairs\n#     same_label_mask = labels.unsqueeze(0) == labels.unsqueeze(1)\n#     diff_label_mask = ~same_label_mask\n    \n#     # Exclude self comparisons\n#     identity_mask = torch.eye(len(labels), dtype=bool)\n#     valid_pos_mask = same_label_mask & ~identity_mask\n    \n#     # Lists for triplets\n#     anchors = []\n#     positives = []\n#     negatives = []\n    \n#     # For each anchor\n#     for anchor_idx in range(len(labels)):\n#         # Skip if no positives\n#         if not valid_pos_mask[anchor_idx].any():\n#             continue\n        \n#         # Get hardest positive\n#         pos_dists = distances[anchor_idx].clone()\n#         pos_dists[~valid_pos_mask[anchor_idx]] = float('inf')\n#         pos_idx = torch.argmin(pos_dists)\n        \n#         # Get hardest negative\n#         neg_dists = distances[anchor_idx].clone()\n#         neg_dists[same_label_mask[anchor_idx]] = float('inf')\n#         neg_idx = torch.argmin(neg_dists)\n        \n#         # Append to lists\n#         anchors.append(anchor_idx)\n#         positives.append(pos_idx)\n#         negatives.append(neg_idx)\n    \n#     return [torch.tensor(anchors), torch.tensor(positives), torch.tensor(negatives)]\n\n# # Define triplet loss function\n# def triplet_loss(embeddings, labels, triplet_indices):\n#     \"\"\"Compute triplet loss with margin\"\"\"\n#     anchors, positives, negatives = triplet_indices\n    \n#     # No triplets case\n#     if len(anchors) == 0:\n#         return torch.tensor(0.0, device=embeddings.device, requires_grad=True)\n    \n#     # Get embeddings for each point in triplets\n#     anchor_embs = embeddings[anchors]\n#     positive_embs = embeddings[positives]\n#     negative_embs = embeddings[negatives]\n    \n#     # Compute distances\n#     pos_distances = F.pairwise_distance(anchor_embs, positive_embs)\n#     neg_distances = F.pairwise_distance(anchor_embs, negative_embs)\n    \n#     # Apply margin and compute loss\n#     losses = F.relu(pos_distances - neg_distances + MARGIN)\n    \n#     return losses.mean()\n\n# # Training function\n# def train_epoch(model, train_loader, optimizer, epoch, device, scaler):\n#     \"\"\"Train for one epoch\"\"\"\n#     model.train()\n#     running_loss = 0.0\n#     processed_batches = 0\n    \n#     # Use tqdm for a progress bar\n#     progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n    \n#     for batch_idx, (images, labels) in enumerate(progress_bar):\n#         try:\n#             # Move data to device\n#             images = images.to(device)\n#             labels = labels.to(device)\n            \n#             # Zero the gradients\n#             optimizer.zero_grad()\n            \n#             # Forward pass with mixed precision\n#             with autocast():\n#                 # Get embeddings\n#                 embeddings = model(images)\n                \n#                 # Get hard triplets\n#                 triplet_indices = get_hard_triplets(embeddings, labels, margin=MARGIN)\n                \n#                 # If no triplets found, continue to next batch\n#                 if len(triplet_indices[0]) == 0:\n#                     progress_bar.set_postfix({'status': 'no triplets'})\n#                     continue\n                \n#                 # Compute triplet loss\n#                 loss = triplet_loss(embeddings, labels, triplet_indices)\n            \n#             # Backward pass with gradient scaling\n#             scaler.scale(loss).backward()\n#             scaler.step(optimizer)\n#             scaler.update()\n            \n#             # Update running loss\n#             running_loss += loss.item()\n#             processed_batches += 1\n            \n#             # Update progress bar\n#             progress_bar.set_postfix({\n#                 'loss': f\"{loss.item():.4f}\",\n#                 'avg_loss': f\"{running_loss / processed_batches:.4f}\",\n#                 'triplets': f\"{len(triplet_indices[0])}\"\n#             })\n                \n#         except Exception as e:\n#             print(f\"Error in batch {batch_idx}: {str(e)}\")\n#             continue\n    \n#     # Calculate average loss for the epoch\n#     epoch_loss = running_loss / max(processed_batches, 1)\n#     return epoch_loss\n\n\n# def evaluate(model, val_loader, device):\n#     \"\"\"Evaluate the model on validation data\"\"\"\n#     model.eval()\n#     embeddings_list = []\n#     labels_list = []\n    \n#     with torch.no_grad():\n#         for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n#             # Move data to device\n#             images = images.to(device)\n            \n#             # Forward pass\n#             embeddings = model(images)\n            \n#             # Store embeddings and labels\n#             embeddings_list.append(embeddings.cpu())\n#             labels_list.append(labels)\n    \n#     # Concatenate all embeddings and labels\n#     all_embeddings = torch.cat(embeddings_list, dim=0)\n#     all_labels = torch.cat(labels_list, dim=0)\n    \n#     # Calculate metrics\n#     return compute_retrieval_metrics(all_embeddings, all_labels)\n\n\n# def compute_retrieval_metrics(embeddings, labels, k_values=[1, 5]):\n#     \"\"\"Compute Top-K retrieval metrics using FAISS\"\"\"\n#     # Convert to numpy for FAISS\n#     embeddings_np = embeddings.numpy()\n#     labels_np = labels.numpy()\n    \n#     # Create FAISS index\n#     d = embeddings_np.shape[1]  # Embedding dimension\n#     index = faiss.IndexFlatL2(d)  # L2 distance for similarity\n#     index.add(embeddings_np)\n    \n#     # Search for nearest neighbors\n#     max_k = max(k_values)\n#     _, indices = index.search(embeddings_np, max_k + 1)  # +1 because first result is self\n    \n#     # Calculate Top-K accuracy\n#     metrics = {}\n#     for k in k_values:\n#         # For each query, check if any of the top-k retrieved items have the same label\n#         # Start from 1 to exclude self\n#         correct = 0\n#         for i, idx_list in enumerate(indices):\n#             query_label = labels_np[i]\n#             retrieved_labels = labels_np[idx_list[1:k+1]]  # Exclude self\n#             if query_label in retrieved_labels:\n#                 correct += 1\n        \n#         accuracy = correct / len(labels_np)\n#         metrics[f'top_{k}_accuracy'] = accuracy\n    \n#     return metrics\n\n\n# # Main training loop\n# def train_model(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs, output_dir, \n#                 resume_path=None):\n#     \"\"\"Full training loop with validation and checkpointing\"\"\"\n#     best_top1 = 0.0\n#     best_model_wts = None\n#     scaler = GradScaler()  # For mixed precision training\n    \n#     # Create output directory if it doesn't exist\n#     os.makedirs(output_dir, exist_ok=True)\n    \n#     # For resuming training from checkpoint\n#     start_epoch = 0\n#     if resume_path and os.path.exists(resume_path):\n#         print(f\"Loading checkpoint from {resume_path}\")\n#         checkpoint = torch.load(resume_path)\n#         model.load_state_dict(checkpoint['model_state_dict'])\n#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n#         if 'scheduler_state_dict' in checkpoint:\n#             scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n#         start_epoch = checkpoint['epoch']\n#         best_top1 = checkpoint.get('best_top1', 0.0)\n#         print(f\"Resuming from epoch {start_epoch} with Top-1 accuracy: {best_top1:.4f}\")\n    \n#     # Training history\n#     history = {\n#         'train_loss': [],\n#         'val_top1': [],\n#         'val_top5': [],\n#         'lr': []\n#     }\n    \n#     print(f\"Starting training at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n#     print(f\"Training for {num_epochs} epochs\")\n    \n#     # Training loop\n#     for epoch in range(start_epoch, num_epochs):\n#         # Get current learning rate\n#         current_lr = optimizer.param_groups[0]['lr']\n#         print(f\"\\nEpoch {epoch+1}/{num_epochs} - Learning Rate: {current_lr:.6f}\")\n        \n#         # Train for one epoch\n#         epoch_loss = train_epoch(model, train_loader, optimizer, epoch, device, scaler)\n#         print(f\"Training loss: {epoch_loss:.4f}\")\n        \n#         # Add to history\n#         history['train_loss'].append(epoch_loss)\n#         history['lr'].append(current_lr)\n        \n#         # Evaluate on validation data\n#         metrics = evaluate(model, val_loader, device)\n#         print(f\"Validation metrics: {metrics}\")\n        \n#         # Add to history\n#         history['val_top1'].append(metrics['top_1_accuracy'])\n#         history['val_top5'].append(metrics['top_5_accuracy'])\n        \n#         # Update learning rate based on training loss\n#         scheduler.step(epoch_loss)\n        \n#         # Save regular checkpoint\n#         checkpoint = {\n#             'epoch': epoch + 1,\n#             'model_state_dict': model.state_dict(),\n#             'optimizer_state_dict': optimizer.state_dict(),\n#             'scheduler_state_dict': scheduler.state_dict(),\n#             'best_top1': best_top1,\n#             'embedding_dim': EMB_DIM,\n#             'history': history\n#         }\n#         torch.save(checkpoint, os.path.join(output_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n        \n#         # Save best model\n#         top1_accuracy = metrics['top_1_accuracy']\n#         if top1_accuracy > best_top1:\n#             best_top1 = top1_accuracy\n#             best_model_wts = copy.deepcopy(model.state_dict())\n#             torch.save(checkpoint, os.path.join(output_dir, 'best_model.pth'))\n#             print(f\"✅ Saved new best model with Top-1 accuracy: {best_top1:.4f}\")\n        \n#         # Plot and save training progress after each epoch\n#         if (epoch + 1) % 2 == 0:  # Every 2 epochs\n#             plt.figure(figsize=(15, 5))\n            \n#             plt.subplot(1, 3, 1)\n#             plt.plot(history['train_loss'])\n#             plt.title('Training Loss')\n#             plt.xlabel('Epoch')\n#             plt.ylabel('Loss')\n#             plt.grid(True)\n            \n#             plt.subplot(1, 3, 2)\n#             plt.plot(history['val_top1'], label='Top-1')\n#             plt.plot(history['val_top5'], label='Top-5')\n#             plt.title('Validation Accuracy')\n#             plt.xlabel('Epoch')\n#             plt.ylabel('Accuracy')\n#             plt.legend()\n#             plt.grid(True)\n            \n#             plt.subplot(1, 3, 3)\n#             plt.plot(history['lr'])\n#             plt.title('Learning Rate')\n#             plt.xlabel('Epoch')\n#             plt.ylabel('LR')\n#             plt.yscale('log')\n#             plt.grid(True)\n            \n#             plt.tight_layout()\n#             plt.savefig(os.path.join(output_dir, 'training_progress.png'))\n#             plt.close()\n    \n#     # Load best model weights\n#     if best_model_wts is not None:\n#         model.load_state_dict(best_model_wts)\n        \n#     print(f\"\\nTraining complete! Best Top-1 accuracy: {best_top1:.4f}\")\n#     print(f\"Best model saved to {os.path.join(output_dir, 'best_model.pth')}\")\n    \n#     # Final history plot\n#     plt.figure(figsize=(15, 5))\n    \n#     plt.subplot(1, 3, 1)\n#     plt.plot(history['train_loss'])\n#     plt.title('Training Loss')\n#     plt.xlabel('Epoch')\n#     plt.ylabel('Loss')\n#     plt.grid(True)\n    \n#     plt.subplot(1, 3, 2)\n#     plt.plot(history['val_top1'], label='Top-1')\n#     plt.plot(history['val_top5'], label='Top-5')\n#     plt.title('Validation Accuracy')\n#     plt.xlabel('Epoch')\n#     plt.ylabel('Accuracy')\n#     plt.legend()\n#     plt.grid(True)\n    \n#     plt.subplot(1, 3, 3)\n#     plt.plot(history['lr'])\n#     plt.title('Learning Rate')\n#     plt.xlabel('Epoch')\n#     plt.ylabel('LR')\n#     plt.yscale('log')\n#     plt.grid(True)\n    \n#     plt.tight_layout()\n#     plt.savefig(os.path.join(output_dir, 'final_training_history.png'))\n    \n#     return model, history\n\n# # Start training\n# print(\"Starting training...\")\n# model, history = train_model(\n#     model=model,\n#     train_loader=train_loader,\n#     val_loader=val_loader,\n#     optimizer=optimizer,\n#     scheduler=scheduler,\n#     device=device,\n#     num_epochs=EPOCHS,\n#     output_dir=OUTPUT_DIR\n# )\n\n# print(\"Training complete! Final results:\")\n# print(f\"Best Top-1 Accuracy: {max(history['val_top1']):.4f}\")\n# print(f\"Best Top-5 Accuracy: {max(history['val_top5']):.4f}\")\n# print(f\"Total training time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:53:45.341591Z","iopub.execute_input":"2025-04-21T18:53:45.341844Z","iopub.status.idle":"2025-04-21T18:53:45.363902Z","shell.execute_reply.started":"2025-04-21T18:53:45.341826Z","shell.execute_reply":"2025-04-21T18:53:45.363076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Training Loop and Evaluation\n\n# Training function\ndef train_epoch(model, train_loader, optimizer, scheduler, epoch, device, scaler):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    running_loss = 0.0\n    \n    # Use tqdm for a progress bar\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n    \n    for batch_idx, (images, labels) in enumerate(progress_bar):\n        # Move data to device\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Zero the gradients\n        optimizer.zero_grad()\n        \n        # Forward pass with mixed precision\n        with autocast():\n            # Get embeddings\n            embeddings = model(images)\n            \n            # Get hard triplets\n            triplet_indices = get_hard_triplets(embeddings, labels, margin=MARGIN)\n            \n            # If no triplets found, continue to next batch\n            if len(triplet_indices[0]) == 0:\n                continue\n            \n            # Compute triplet loss\n            loss = triplet_loss(embeddings, labels, triplet_indices)\n        \n        # Backward pass with gradient scaling\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        # Update running loss\n        running_loss += loss.item()\n        \n        # Update progress bar\n        progress_bar.set_postfix({\n            'loss': f\"{loss.item():.4f}\",\n            'avg_loss': f\"{running_loss / (batch_idx + 1):.4f}\"\n        })\n    \n    # Calculate average loss for the epoch\n    epoch_loss = running_loss / len(train_loader)\n    return epoch_loss\n\n\ndef evaluate(model, val_loader, device):\n    \"\"\"Evaluate the model on validation data\"\"\"\n    model.eval()\n    embeddings_list = []\n    labels_list = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n            # Move data to device\n            images = images.to(device)\n            \n            # Forward pass\n            embeddings = model(images)\n            \n            # Store embeddings and labels\n            embeddings_list.append(embeddings.cpu())\n            labels_list.append(labels)\n    \n    # Concatenate all embeddings and labels\n    all_embeddings = torch.cat(embeddings_list, dim=0)\n    all_labels = torch.cat(labels_list, dim=0)\n    \n    # Calculate metrics (using k-nearest neighbors for validation)\n    # For this task, we'll compute Top-1 and Top-5 accuracy\n    return compute_retrieval_metrics(all_embeddings, all_labels)\n\n\ndef compute_retrieval_metrics(embeddings, labels, k_values=[1, 5]):\n    \"\"\"Compute Top-K retrieval metrics using FAISS\"\"\"\n    # Convert to numpy for FAISS\n    embeddings_np = embeddings.numpy()\n    labels_np = labels.numpy()\n    \n    # Create FAISS index\n    d = embeddings_np.shape[1]  # Embedding dimension\n    index = faiss.IndexFlatL2(d)  # L2 distance for similarity\n    index.add(embeddings_np)\n    \n    # Search for nearest neighbors\n    max_k = max(k_values)\n    _, indices = index.search(embeddings_np, max_k + 1)  # +1 because first result is self\n    \n    # Calculate Top-K accuracy\n    metrics = {}\n    for k in k_values:\n        # For each query, check if any of the top-k retrieved items have the same label\n        # Start from 1 to exclude self\n        correct = 0\n        for i, idx_list in enumerate(indices):\n            query_label = labels_np[i]\n            retrieved_labels = labels_np[idx_list[1:k+1]]  # Exclude self\n            if query_label in retrieved_labels:\n                correct += 1\n        \n        accuracy = correct / len(labels_np)\n        metrics[f'top_{k}_accuracy'] = accuracy\n    \n    return metrics\n\n\n# Main training loop\ndef train_model(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs, output_dir):\n    \"\"\"Full training loop with validation and checkpointing\"\"\"\n    best_top1 = 0.0\n    scaler = GradScaler()  # For mixed precision training\n    \n    # Create output directory if it doesn't exist\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        \n        # Train for one epoch\n        epoch_loss = train_epoch(model, train_loader, optimizer, scheduler, epoch, device, scaler)\n        print(f\"Training loss: {epoch_loss:.4f}\")\n        \n        # Evaluate on validation data\n        metrics = evaluate(model, val_loader, device)\n        print(f\"Validation metrics: {metrics}\")\n        \n        # Update learning rate based on validation performance\n        scheduler.step(epoch_loss)\n        \n        # Save checkpoint if improved\n        top1_accuracy = metrics['top_1_accuracy']\n        if top1_accuracy > best_top1:\n            best_top1 = top1_accuracy\n            checkpoint = {\n                'epoch': epoch + 1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'best_top1': best_top1,\n                'embedding_dim': EMB_DIM\n            }\n            torch.save(checkpoint, os.path.join(output_dir, 'best_model.pth'))\n            print(f\"Saved new best model with Top-1 accuracy: {best_top1:.4f}\")\n    \n    return model\n\n# Start training\nprint(\"Starting training...\")\ntrain_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    device=device,\n    num_epochs=EPOCHS,\n    output_dir=OUTPUT_DIR\n)\n\nprint(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:53:45.364914Z","iopub.execute_input":"2025-04-21T18:53:45.365177Z","iopub.status.idle":"2025-04-21T18:53:47.115722Z","shell.execute_reply.started":"2025-04-21T18:53:45.365161Z","shell.execute_reply":"2025-04-21T18:53:47.114829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}